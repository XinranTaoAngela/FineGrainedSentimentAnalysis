{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                           selftext  \\\n",
      "0  1gzxiij  Background: I am an Internal Medicine physicia...   \n",
      "1  1gzvuba  I have an issue and it plague's my brain on a ...   \n",
      "2  1gzv22e  Medicare payments are scheduled to decrease in...   \n",
      "3  1gzubf1  [The Perverse Consequences of Tuition-Free Med...   \n",
      "4  1gzhrmq  I read an article on bloomberg that seems pert...   \n",
      "\n",
      "                                            emotions  confidence  \\\n",
      "0         confidence,satisfaction,hope,trust_medical           1   \n",
      "1                                      anxiety,anger           0   \n",
      "2  confidence,satisfaction,anxiety,hope,trust_med...           1   \n",
      "3                        anxiety,anger,trust_medical           0   \n",
      "4                        anxiety,anger,trust_medical           0   \n",
      "\n",
      "   satisfaction  hope  trust_medical  anxiety  anger  \n",
      "0             1     1              1        0      0  \n",
      "1             0     0              0        1      1  \n",
      "2             1     1              1        1      0  \n",
      "3             0     0              1        1      1  \n",
      "4             0     0              1        1      1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(\"/Users/angelatao/Desktop/fine_gained_sentiment_analysis/data/Labeled_Reddit_Data.csv\")\n",
    "\n",
    "# 定义所有可能的情感类别\n",
    "all_emotions = [\"confidence\", \"satisfaction\", \"hope\", \"trust_medical\", \"anxiety\", \"anger\"]\n",
    "\n",
    "# 初始化所有情感列为 0\n",
    "for emotion in all_emotions:\n",
    "    df[emotion] = df['emotions'].apply(lambda x: 1 if emotion in x else 0)\n",
    "\n",
    "# 现在 df 里每个情感都是独立的二进制列\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdamW' from 'transformers' (/opt/anaconda3/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaTokenizer, RobertaForSequenceClassification, AdamW\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdamW' from 'transformers' (/opt/anaconda3/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 检测 MPS（Apple GPU）或 CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(\"/Users/angelatao/Desktop/fine_gained_sentiment_analysis/data/Labeled_Reddit_Data.csv\")\n",
    "\n",
    "# 定义所有可能的情感类别\n",
    "all_emotions = [\"confidence\", \"satisfaction\", \"hope\", \"trust_medical\", \"anxiety\", \"anger\"]\n",
    "\n",
    "# 将情感转换为二进制向量\n",
    "for emotion in all_emotions:\n",
    "    df[emotion] = df['emotions'].apply(lambda x: 1 if emotion in x else 0)\n",
    "\n",
    "# 划分训练和验证集\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"selftext\"].tolist(), df[all_emotions].values.tolist(), test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# 载入 tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# 自定义 Dataset\n",
    "class RedditDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "# 创建 Dataset 和 DataLoader\n",
    "train_dataset = RedditDataset(train_texts, train_labels)\n",
    "val_dataset = RedditDataset(val_texts, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# 加载 RoBERTa 模型\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(all_emotions))\n",
    "model.to(device)\n",
    "\n",
    "# 选择优化器和损失函数\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "\n",
    "# 训练参数\n",
    "EPOCHS = 3\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "val_auc_scores = []\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # 验证模式\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits.sigmoid().cpu().numpy()  # 转换成概率\n",
    "            loss = loss_fn(torch.tensor(logits), torch.tensor(labels))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            true_labels.extend(labels)\n",
    "            predictions.extend(logits)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    f1 = f1_score(true_labels, np.array(predictions) > 0.5, average=\"macro\")\n",
    "    auc = roc_auc_score(true_labels, predictions, average=\"macro\")\n",
    "\n",
    "    val_f1_scores.append(f1)\n",
    "    val_auc_scores.append(auc)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f} | F1 Score: {f1:.4f} | AUC Score: {auc:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save_pretrained(\"roberta_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"roberta_sentiment_model\")\n",
    "\n",
    "# 训练可视化\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, EPOCHS + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, EPOCHS + 1), val_f1_scores, label=\"Validation F1 Score\")\n",
    "plt.plot(range(1, EPOCHS + 1), val_auc_scores, label=\"Validation AUC Score\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Metrics\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
